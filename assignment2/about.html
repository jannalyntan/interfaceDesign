<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Assignment 2</title>

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Bodoni+Moda:ital,opsz,wght@0,6..96,400..900;1,6..96,400..900&family=Lexend:wght@100..900&family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100..900;1,100..900&display=swap"
      rel="stylesheet"
    />

    <!-- Styles -->
    <link rel="stylesheet" href="about.css" />

    <!-- Scripts -->
    <script src="https://unpkg.com/tone" defer></script>
    <!-- <script src="script.js" defer></script> -->
    <script src="about.js" defer></script>
  </head>

  <body>
    <section class="container" id="Navigation">
      <!-- Navigation -->
      <nav id="tab-groups">
        <button
          class="tab-groups"
          id="Play"
          onclick="window.location.href='index.html'"
        >
          play.
        </button>
        <button
          class="tab-groups"
          id="About"
          onclick="window.location.href='about.html'"
        >
          about.
        </button>
      </nav>
      <hr style="margin-right: -10%; margin-left: -10%; margin-top: -450px" />
    </section>

    <section class="content" style="margin-top: -565px">
      <div id="heading">
        <p>jump to</p>
        <div class="sidebyside">
          <button class="project">project conceptualisation.</button>
          <button class="project">technical conceptualisation.</button>
          <button class="project">peer review.</button>
        </div>
      </div>

      <h1>Project Conceptualisation</h1>
      <p style="margin-top: -10px">
        My project explores the transformation of typing, a common, everyday
        computer interaction, into audio cues. Using novel input techniques to
        convert text into sound. The concept was inspired by TikTok videos in
        which users generate unique sounds from their names. From there I began
        imagining what my own name would sound like and then expanded this into
        the broader design inquiry: “What will this text sound like?”
      </p>

      <a
        href="https://www.tiktok.com/@ben_makes_names_to_music/video/6945646958623132933?is_from_webapp=1&sender_device=pc"
        target="_blank"
      >
        <button>link to tiktok.</button>
      </a>

      <div class="sidebyside">
        <p class="left">
          I developed an interaction where users can type words and immediately
          hear corresponding sounds, effectively turning simple text into short,
          dynamic audio pieces. Because the project is primarily text-driven, I
          deliberately designed a minimalist and clean layout to ensure that
          sound remains the primary focus. I researched a variety of website
          styles, particularly those emphasizing typography and clarity, and
          initially planned to replicate a similarly structured aesthetic.
        </p>

        <div class="right">
          <img
            src="images/reference-1.png"
            alt="reference-1"
            style="width: 700px"
          />
          <p class="subtext" style="margin-top: -20px">
            Previous reference board <br />
            Images from Pinterest
          </p>
        </div>
      </div>

      <div class="sidebyside">
        <div class="left">
          <img
            src="images/reference-2.png"
            alt="reference-1"
            style="width: 700px"
          />
          <p class="subtext">
            Reference board <br />
            Images from Pinterest
          </p>
        </div>

        <p class="right">
          However, during development, I realized that my initial design didn’t
          quite match the generated sounds. I began experimenting with both the
          visuals and the audio to make them feel more aligned. While exploring
          different options, I noticed that the audio resembled wind chimes,
          which inspired a shift toward a Zen-like visual style. I kept the
          layout minimal so the audio could guide the visual atmosphere. This
          approach ensured that the interaction stayed focused on the auditory
          experience rather than relying on symbols or complex graphics,
          creating a cohesive and conceptually consistent UI.
        </p>
      </div>

      <h2>Layout guide</h2>

      <div class="sidebyside" style="margin-right: 10%; margin-left: 10%">
        <div
          class="hoverover"
          data-hover="This layout was developed using the previous reference board as a guide."
        >
          <img
            src="images/Layout-1.png"
            alt="Layout-1"
            style="width: 650px; height: 400px"
          />
        </div>

        <div
          class="hoverover"
          data-hover="This was done after finalising on the reference board. Using the circles as found on the reference board to showcase the zen like feeling."
        >
          <img
            src="images/Layout-2.png"
            alt="Layout-2"
            style="width: 650px; height: 400px"
          />
        </div>
      </div>

      <br />
      <br />

      <h1>Technical Conceptualisation</h1>
      <p style="margin-top: -10px">
        For the advanced techniques, I implemented a “generate” button using
        Math.random(). When clicked, it selects a word at random from a
        predefined list, which fits naturally into the interaction and goes well
        with my desired interaction.

        <br />
        <br />
        The system’s core interactions, implemented using JavaScript and
        Tone.js, include:
      </p>

      <div class="sidebyside2">
        <div class="background">
          <h2>1. Sound While Typing</h2>
          <p>Each keys triggers a corresponding note that plays when typed.</p>
        </div>

        <div class="background">
          <h2>2. Play Button Playback</h2>
          <p>Sequentially plays all letters that are typed in.</p>
        </div>

        <div class="background">
          <h2>3. Visual Tracking of Letters</h2>
          <p>Highlights the current character being played in real time.</p>
        </div>
      </div>

      <p>
        To support these interactions, I mapped the keyboard so that each letter
        and symbol corresponded to a distinct note. Symbols such as periods or
        spaces were mapped to chords, expanding the musical possibilities.
        Uppercase letters were mapped as sharps of their lowercase equivalents,
        increasing the variety of sounds.
      </p>

      <div class="sidebyside" style="margin-top: 50px">
        <div class="left">
          <h2>Interaction 1: Sound While Typing</h2>
          <p style="margin-left: -1px">
            This interaction was implemented using an input event listener on
            the &lt;textarea&gt;. When the user types, Tone.js’s
            triggerAttackRelease method plays the corresponding note. While
            technically straightforward, this required mapping of characters to
            musical notes to ensure it was the right pitch, allowing the sound
            to fit better with the aesthetic of the page.
          </p>
        </div>
        <div class="right">
          <img src="images/code.png" alt="code-1" style="height: 400px" />
        </div>
      </div>

      <div class="sidebyside" style="margin-top: 50px">
        <div class="left">
          <img src="images/code.png" alt="code-1" style="height: 400px" />
        </div>
        <div class="right">
          <h2>Interaction 2: Play Button Playback</h2>
          <p style="margin-right: -1px">
            This interaction was implemented by iterating through all the
            characters in the text area and playing each one using
            triggerAttackRelease. As the code progresses, each character is read
            in sequence, triggering the corresponding note or chord based on the
            predefined mappings. This allows the text to be “sounded out” in
            real time, creating an audio piece made by letters and punucation.
          </p>
        </div>
      </div>

      <h2>Interaction 3: Visual Tracking of Letters</h2>

      <p>
        This interaction presented a significant technical challenge. The key
        difficulty was tracking individual letters within a &lt;textarea&gt; and
        updating their visual state to reflect the corresponding sound being
        played. Standard &lt;textarea&gt; elements do not allow per-character
        styling, so I implemented a layered solution: each typed character was
        mirrored as a separate &lt;span&gt; within an overlapping &lt;div&gt;.
        <br />
        This approach enabled real-time tracking and synchronisation of visual
        with audio playback.

        <br />
        Initially, I used a standard &lt;input&gt; field for typing and
        highlighting. However, this approach failed because input fields cannot
        style individual character, and styling only applies to the text. Hence,
        I tried the overlay option. With this implementation, each character
        could be individually highlighted as it played, providing clear visual
        feedback that reinforces the auditory experience.
      </p>
    </section>
  </body>
</html>
